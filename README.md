# SIGVID
The reading list for the Special Interest Group on Visual Information Description

## Image Captioning
### Level 0
* [Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)](https://arxiv.org/abs/1412.6632)[ICLR 2015 Oral]
* [Sequence to Sequence -- Video to Text](https://arxiv.org/abs/1505.00487)[ICCV 2015]
* [What value do explicit high level concepts have in vision to language problems?](https://arxiv.org/abs/1506.01144)[CVPR 2016]


### Level 1
* [Learning like a Child: Fast Novel Visual Concept Learning from Sentence Descriptions of Images](https://arxiv.org/abs/1504.06692)[ICCV 2015]
* [Show, Attend and Tell: Neural Image Caption Generation with Visual Attention](https://arxiv.org/abs/1502.03044)[ICML 2015]
* [DenseCap: Fully Convolutional Localization Networks for Dense Captioning](https://arxiv.org/abs/1511.07571)[CVPR 2016 Oral]
* [Image Captioning with Deep Bidirectional LSTMs](https://arxiv.org/abs/1604.00790)[ACMMM 2016 Oral]




## Video Captioning
* [Early Embedding and Late Reranking for Video Captioning](lixirong.net/pub/mm2016-video2text.pdf)[ACMMM 2016 Grand Challenge Award]
* [Video Paragraph Captioning Using Hierarchical Recurrent Neural Networks](https://arxiv.org/abs/1510.07712)[CVPR 2016 Oral]
* [Frame-and Segment-Level Features and Candidate Pool Evaluation for Video Caption Generation](https://arxiv.org/abs/1608.04959)[best in MSR Video to Language Challenge]




## Visual Question Answering
* [VQA: Visual Question Answering](https://arxiv.org/abs/1505.00468)[ICCV 2015]


## Theories of DNN
* [Identifying and attacking the saddle point problem in high-dimensional non-convex optimization](http://papers.nips.cc/paper/5486-identifying-and-attacking-the-saddle-point-problem-in-high-dimensional-non-convex-optimization.pdf)[NIPS 2014]
* [The loss surfaces of multilayer networks](http://www.jmlr.org/proceedings/papers/v38/choromanska15.pdf)[JMLR 2015]
* [On the expressive power of deep neural networks](https://arxiv.org/pdf/1606.05336.pdf)[ML/AI arxiv 2016] 


## Miscellaneous
* [Spatial Transformer Networks](https://arxiv.org/abs/1506.02025)[NIPS 2015]




## Appendix
### Other Reading Lists
* [Deep Learning Papers Reading Roadmap](https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap)
* [Awesome Deep Learning](https://github.com/ChristosChristofidis/awesome-deep-learning)
* [Awesome Deep Vision](https://github.com/kjw0612/awesome-deep-vision)
* [Awesome - Most Cited Deep Learning Papers](https://github.com/terryum/awesome-deep-learning-papers#caption)


### Project Demo
#### NeuralTalk
* [NeuralTalk Github homepage](https://github.com/karpathy/neuraltalk)
* [An ios app](http://www.theverge.com/2016/3/10/11187816/neuraltalk-ai-scry-app)

#### DenseCap
* [DenseCap results browser](http://cs.stanford.edu/people/karpathy/densecap/browser/)
* [Dense captioning of Boston Dynamics Atlas Robot](https://vimeo.com/173025372)

#### Deeper LSTM+ normalized CNN for Visual Question Answering
* [Github homepage](https://github.com/VT-vision-lab/VQA_LSTM_CNN)
* [A live demo](http://cloudcv.org/vqa/)

#### Faster RCNN
* [anchor_target_layer](https://github.com/rbgirshick/py-faster-rcnn/blob/master/lib/rpn/anchor_target_layer.py#L65)
